{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07dc4371",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## a. Formulating a knowledge base (KB) using propositional logic\n",
    "### The given puzzle is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e6b46",
   "metadata": {},
   "source": [
    "1. Chen's mark was lower than the mark of the person who studied French.<p>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1643f9f8",
   "metadata": {},
   "source": [
    "2. The three people are Brian, the person who studied History, the person who graduated on the 2nd.<p>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2fc826",
   "metadata": {},
   "source": [
    "3. Chen scored 70%, unless she studied history in which case her mark was 65%.<p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55558bab",
   "metadata": {},
   "source": [
    "4. The mark of the person who graduated on the 3rd was 5% higher than Chen's. <p>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca8b8fb",
   "metadata": {},
   "source": [
    "5. Anjali did not graduate on the 2nd.<p>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88b95c",
   "metadata": {},
   "source": [
    "### Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1017ccc",
   "metadata": {},
   "source": [
    "a. Brian didn't study history or graduate on 2nd. (From 2)<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd5deba",
   "metadata": {},
   "source": [
    "b. Chen graduated on 2nd. (From 1,2 and 5)<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a5a297",
   "metadata": {},
   "source": [
    "c. Chen scored 70%. (From 3)<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d3129",
   "metadata": {},
   "source": [
    "d. Chen studied Geography. (From 1,2,3,b and c)<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7979f616",
   "metadata": {},
   "source": [
    "e. Anjali studied History. (From 2 and 5) <p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435ec93",
   "metadata": {},
   "source": [
    "f. Anjali scored 65%. (From 3 and e) <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb23c16",
   "metadata": {},
   "source": [
    "g. Anjali graduated on 4th. (From 4 and f) <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febcecf4",
   "metadata": {},
   "source": [
    "h. Brian studied French. (From d and e) <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e793b",
   "metadata": {},
   "source": [
    "i. Brian scored 75%. (From c and f) <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5983a4",
   "metadata": {},
   "source": [
    "j. Brian graduated on 3rd. (From b and g)<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe93fd9",
   "metadata": {},
   "source": [
    "So for final solution, we have,\n",
    "\n",
    "|Name  |Graduated on|Subject  |Score|\n",
    "|------|------------|---------|-----|\n",
    "|Chen  |2nd         |Geography|70%. |\n",
    "|Brian |3rd         |French.  |75%. |\n",
    "|Anjali|4th         |History. |65%. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714542a",
   "metadata": {},
   "source": [
    "### Defining the propositions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b78fe6",
   "metadata": {},
   "source": [
    "AF: Anjali studied French, AG: Anjali studied Geography, AH: Anjali studied History.<p>\n",
    "BF: Brian studied French, BG: Brian studied Geography, BH: Brian studied History.<p>\n",
    "CF: Chen studied French, CG: Chen studied Geography, CH: Chen studied History.<p>\n",
    "A2: Anjali graduated on 2nd, A3: Anjali graduated on 3rd, A4: Anjali graduated on 4th.<p>\n",
    "B2: Brian graduated on 2nd, B3: Brian gradutaed on 3rd, B4: Brian graduated on 4th.<p>\n",
    "C2: Chen graduated on 2nd, C3: Chen graduated on 3rd, C4: Chen graduated on 4th.<p>\n",
    "A65: Anjali scored 65, A70: Anjali scored 70, A75: Anjali scored 75.<p>\n",
    "B65: Brian scored 65, B70: Brian scored 70, B75: Brian scored 75.<p>\n",
    "C65: Chen scored 65, C70: Chen scored 70, C75: Chen scored 75.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bbbe49",
   "metadata": {},
   "source": [
    "### For knowledge base representation, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb38c755",
   "metadata": {},
   "source": [
    "1. Chen's mark was lower than the mark of the person who studied French.<p>\n",
    "    Clue 1: So Chen's mark is not 75 and he didnt study French.\n",
    "    \n",
    "      $ R1: \\neg CF \\land \\neg C75 $<p>\n",
    "    Clue 2: If Chen didnt study French, then she studied either Geography or History.\n",
    "   \n",
    "      $ R2: CG \\lor CH$<p>\n",
    "    Clue 3: We know Chen didnt study French. So either Anjali or Brian studied French. So, we have for Anjali studying French,\n",
    "        \n",
    "      $ R3: AF \\implies\\ (BG \\lor BH) $<p>\n",
    "        \n",
    "        And for Brian studying French,\n",
    "      $ R4: BF \\implies\\ (AG \\lor AH) $<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3facae6",
   "metadata": {},
   "source": [
    "2. The three people are Brian, the person who studied History, the person who graduated on the 2nd.<p>\n",
    "    \n",
    "    Clue 1: Since Brian didnt study history, he either studied Geography or French. Also, he didnt graduate on 2nd so he graduated on either 3rd or 4th.\n",
    "    \n",
    "    $ R5: ((BG \\lor BF)$<p>\n",
    "    $ R6: (B3 \\lor B4)$ <p>\n",
    "    $ R7: (\\neg BH \\land \\neg B2))$<p> \n",
    "    $ R8: (AH \\lor CH)$<p>\n",
    "    $ R9: (C2 \\lor A2)$<p>\n",
    "        \n",
    "    Clue 2: If Anjali studied History, we have,\n",
    "        \n",
    "    $ R10: AH \\implies\\ C2$<p>\n",
    "    $ R11: AH \\implies\\ (A3 \\lor A4)$<p>\n",
    "    $ R12: AH \\implies\\ (CG \\lor CF)$\n",
    "    \n",
    "    Clue 3: If Chen studied History, we have,\n",
    "     \n",
    "    $ R13: CH \\implies\\ (AG \\lor AF)$<p>\n",
    "    $ R14: CH \\implies\\ (C3 \\lor C4)$\n",
    "    \n",
    "    Clue 4: If Chen graduated on 2nd then,\n",
    "        \n",
    "    $ R15: C2 \\implies\\ (A3 \\lor A4)$\n",
    "        \n",
    "    Clue 5: For Anjali graduating on 2nd,   \n",
    "        \n",
    "    $ R16: A2 \\implies\\ (C3 \\lor C4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448d1b33",
   "metadata": {},
   "source": [
    "3. Chen scored 70%, unless she studied history in which case her mark was 65%.<p>\n",
    "    \n",
    "    Clue 1: For Chen scoring 70, we have,\n",
    "    \n",
    "    R17: $ CG \\implies\\ C70 $<p>\n",
    "    R18: $ CF \\implies\\ C70 $<p>\n",
    "        \n",
    "    We know Chen's mark is lower than the person who studied French. So,<p>\n",
    "    \n",
    "    R19: $ BF \\implies\\ B75$<p>\n",
    "    R20: $ AF \\implies\\ A75$<p>\n",
    "    \n",
    "    Clue 2: For Chen studying history, we have,\n",
    "        \n",
    "    R21: $ CH \\implies\\ C65$<p>\n",
    "    R22: $ CH \\implies\\ (BF \\lor B70) $<p>\n",
    "    R23: $ CH \\implies\\ (AF \\lor A70)$\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bf877",
   "metadata": {},
   "source": [
    "4. The mark of the person who graduated on the 3rd was 5% higher than Chen's. \n",
    "    \n",
    "    Clue 1: Since the person who graduated on the 3rd was 5% higher than Chen chen couldnt have graduated on 3rd. Also he wouldnt have the highest score. And either Anjali or Brian graduated on 3rd. \n",
    "    \n",
    "    R24: $\\neg C3 \\land \\neg C75$\n",
    "    R25: $ A3 \\lor B3$\n",
    "    \n",
    "    Clue 2: Chen must have graduated on 2nd or 4th.\n",
    "    \n",
    "    R26: $C4 \\lor C2$\n",
    "    \n",
    "    Clue 3: Since Chen's mark is 5% lower than Anjali or Brian's mark. We have,\n",
    "    \n",
    "    R27: $C70 \\implies\\ (A75 \\lor B75)$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7616d84",
   "metadata": {},
   "source": [
    "5. Anjali did not graduate on the 2nd.<p>\n",
    "    Clue 1: This means she graduated on either 3rd or 4th.<p>\n",
    "    R28: $\\neg A2$\n",
    "    R29: $(A3 \\lor A4)$\n",
    "     \n",
    "    Clue 2: Since Anjali didnt graduate on 2nd. Either Brian or Chen graduate on 2nd.\n",
    "        \n",
    "    R30: $B2 \\implies\\ (C3 \\lor C4)$<p>\n",
    "    R31: $B2 \\implies\\ (A3 \\lor A4)$<p>\n",
    "    R32: $C2 \\implies\\ (B3 \\lor B4)$<p>\n",
    "    R33: $C2 \\implies\\ A4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c25c7",
   "metadata": {},
   "source": [
    "For 3 students with 3 subjects, 3 scores and 3 graduation dates, we have the expression as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d986d105",
   "metadata": {},
   "source": [
    "$f$(P,Q,R) = $(P \\land \\neg Q \\land \\neg R)\\lor(\\neg P \\land Q \\land \\neg R)\\lor(\\neg P \\land \\neg Q \\land R)$<p>\n",
    "    This can be interpreted as:<p>\n",
    "    $(P \\lor Q \\lor R) \\land (\\neg P \\lor \\neg Q) \\land (\\neg P \\lor \\neg R)\\land (\\neg Q \\lor \\neg R)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cbe6a6",
   "metadata": {},
   "source": [
    "6. Each student studied only one subject. <p>\n",
    "    R34 : $f$(AF,AG,AH)<p>\n",
    "    R35 : $f$(BF,BG,BH)<p>\n",
    "    R36 : $f$(CF,CG,CH)<p>\n",
    "                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bfa397",
   "metadata": {},
   "source": [
    "7. Each student graduated on a different day.<p>\n",
    "    R37 : $f$(A2,A3,A4)<p>\n",
    "    R38: $f$(B2,B3,B4)<p>\n",
    "    R39: $f$(C2,C3,C4)<p>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710847c2",
   "metadata": {},
   "source": [
    "8. Each student scored different scores.<p>\n",
    "    R40: $f$(A65,A70,A75)<p>\n",
    "    R41: $f$(B65,B70,B75)<p>\n",
    "    R42: $f$(C65,C70,C75)<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c332dbd",
   "metadata": {},
   "source": [
    "9. For individual subject,scores and marks, we have<p>\n",
    "$R_{43}$: $f(AH, BH, CH)$ <p>\n",
    "$R_{44}$: $f(AG, BG, CG)$<p>\n",
    "$R_{45}$: $f(AF, BF, CF)$<p>\n",
    "$R_{46}$: $f(A65, B65, C65)$<p>\n",
    "$R_{47}$: $f(A70, B70, C70)$<p>\n",
    "$R_{48}$: $f(A75, B75, C75)$<p>\n",
    "$R_{49}$: $f(A2, B2, C2)$<p>\n",
    "$R_{50}$: $f(A3, B3, C3)$<p>\n",
    "$R_{51}$: $f(A4, B4, C4)$<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a600ee",
   "metadata": {},
   "source": [
    "Adopting the relatively natural ordering\n",
    "|AF|BF|CF|AG|BG|CG|AH|BH|CH|A2|B2|C2|A3|B3|C3|A4|B4|C4|A65|B65|C65|A70|B70|C70|A75|B75|C75|\n",
    "|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|---|---|---|---|---|---|---|---|---|\n",
    "|0 |1 |2 |3 |4 |5 |6 |7 |8 |9 |10|11|12|13|14|15|16|17|18 |19 |20 |21 |22 |23 |24 |25 |26 |\n",
    "\n",
    "we now "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66376ecb",
   "metadata": {},
   "source": [
    "## b. Backtracking search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc826f69",
   "metadata": {},
   "source": [
    "### First converting the constraints into Conjunctive Normal Form (CNF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe32ca5",
   "metadata": {},
   "source": [
    "$1. \\neg CF \\land \\neg C75$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866e5ce5",
   "metadata": {},
   "source": [
    "$2. CG \\lor CH$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b764f",
   "metadata": {},
   "source": [
    "$3. AF \\implies\\ (BG \\lor BH)$<p>\n",
    "    $ \\neg AF \\lor (BG \\lor BH)$<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95544ed4",
   "metadata": {},
   "source": [
    "$4. BF \\implies\\ (AG \\lor AH)$<p>\n",
    "    $ \\neg BF \\lor (AG \\lor AH)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19987f0",
   "metadata": {},
   "source": [
    "$5. \\neg BH \\lor \\neg B2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c02c1",
   "metadata": {},
   "source": [
    "$6. BG \\lor BF$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e395d",
   "metadata": {},
   "source": [
    "$7.B3 \\lor B4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf94e42",
   "metadata": {},
   "source": [
    "$8. AH \\lor CH$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a186ac",
   "metadata": {},
   "source": [
    "$9. A2 \\lor C2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a2095",
   "metadata": {},
   "source": [
    "$10. AH \\implies\\ C2$<p>\n",
    "    $ \\neg AH \\lor C2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbed02",
   "metadata": {},
   "source": [
    "$11. AH \\implies\\ A3 \\lor A4$<p>\n",
    "    $ \\neg AH \\lor (A3 \\lor A4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642a36e",
   "metadata": {},
   "source": [
    "$12. AH \\implies\\ (CG \\lor CF)$<p>\n",
    "    $ \\neg AH \\lor (CG \\lor CF)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f98273",
   "metadata": {},
   "source": [
    "$13. CH \\implies\\ (AG \\lor AF)$<p>\n",
    "   $ \\neg CH \\lor (AG \\lor AF)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b2c63",
   "metadata": {},
   "source": [
    "$14. CH \\implies\\ (C3 \\lor C4)$<p>\n",
    "    $ \\neg CH \\lor (C3 \\lor C4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912f70c",
   "metadata": {},
   "source": [
    "$15. C2 \\implies\\ (A3 \\lor A4)$<p>\n",
    "    $ \\neg C2 \\lor (A3 \\lor A4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee3cd5f",
   "metadata": {},
   "source": [
    "$16. A2 \\implies\\ (C3 \\lor C4)$<p>\n",
    "    $ \\neg A2 \\lor (C3 \\lor C4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1da8a5",
   "metadata": {},
   "source": [
    "$17. CG \\implies\\ C70$<p>\n",
    "$ \\neg CG \\lor C70$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94bac5",
   "metadata": {},
   "source": [
    "$18. CF \\implies\\ C70$<p>\n",
    "    $ \\neg CF \\lor C70$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abedec",
   "metadata": {},
   "source": [
    "$19. BF \\implies\\ B75 $<p>\n",
    "    $ \\neg BF \\lor B75$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e10cf6",
   "metadata": {},
   "source": [
    "$20. AF \\implies A75$<p>\n",
    "    $ \\neg AF \\lor A75$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680873e3",
   "metadata": {},
   "source": [
    "$21. CH \\implies\\ C65$<p>\n",
    "    $\\neg CH \\lor C65$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8154264c",
   "metadata": {},
   "source": [
    "$22. CH \\implies\\ (BF \\lor B70)$<p>\n",
    "$ \\neg CH \\lor (BF \\lor B70)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae3afc",
   "metadata": {},
   "source": [
    "$23. CH \\implies\\ (AF \\lor A70)$<p>\n",
    "$ \\neg CH \\lor (AF \\lor A70)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994612b",
   "metadata": {},
   "source": [
    "$24. \\neg C3 \\land \\neg C75$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e49bf4",
   "metadata": {},
   "source": [
    "$25. A3 \\lor B3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde521d",
   "metadata": {},
   "source": [
    "$26. C4 \\lor C2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a188a03",
   "metadata": {},
   "source": [
    "$27. C70 \\implies\\ (A75 \\lor B75)$<p>\n",
    "    $ \\neg C70 \\lor (A75 \\lor B75)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe720f1",
   "metadata": {},
   "source": [
    "$28. \\neg A2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c3c0f",
   "metadata": {},
   "source": [
    "$29. A3 \\lor A4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14bf008",
   "metadata": {},
   "source": [
    "$30. B2 \\implies\\ (C3 \\lor C4)$<p>\n",
    "    $ \\neg B2 \\lor (C3 \\lor C4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0997a5d2",
   "metadata": {},
   "source": [
    "$31. B2 \\implies\\ (A3 \\lor A4)$<p>\n",
    "    $ \\neg B2 \\lor (A3 \\lor A4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26b630",
   "metadata": {},
   "source": [
    "$32. C2 \\implies\\ (B3 \\lor B4)$<p>\n",
    "    $ \\neg C2 \\lor (B3 \\lor B4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f6fdc",
   "metadata": {},
   "source": [
    "$.33. C2 \\implies\\ A4$<p>\n",
    "    $ \\neg C2 \\lor A4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb88577",
   "metadata": {},
   "source": [
    "$34. (P \\land \\neg Q \\land \\neg R) \\lor (\\neg P \\land Q \\land \\neg R) \\lor (\\neg P \\land \\neg Q \\land R)$<p> \n",
    "    $(P \\lor Q \\lor R) \\land (\\neg P \\lor \\neg Q) \\land (\\neg P \\lor \\neg R) \\land (\\neg Q \\lor \\neg R)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36744c85",
   "metadata": {},
   "source": [
    "### Since the above equation is repeated in 9 constraints, we take the values of the constraints in the equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b949a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateKB(Clauses, Model):\n",
    "    EvaluatedClauses = []\n",
    "    for clause in Clauses:\n",
    "        EvaluatedLiterals = []\n",
    "        for literal in clause:\n",
    "            if literal[0] == '~':\n",
    "                negated_literal = literal[1:]\n",
    "                if Model.get(negated_literal) is None:\n",
    "                    EvaluatedLiterals.append(None)\n",
    "                else:\n",
    "                    EvaluatedLiterals.append(not Model[negated_literal])\n",
    "            else:\n",
    "                if Model.get(literal) is None:\n",
    "                    EvaluatedLiterals.append(None)\n",
    "                else:\n",
    "                    EvaluatedLiterals.append(Model[literal])\n",
    "        if True in EvaluatedLiterals:\n",
    "            EvaluatedClauses.append(True)\n",
    "        elif None in EvaluatedLiterals:\n",
    "            EvaluatedClauses.append(None)\n",
    "        else:\n",
    "            EvaluatedClauses.append(False)\n",
    "\n",
    "    if all(i is True for i in EvaluatedClauses):\n",
    "        EvaluatedKB = True\n",
    "    elif False in EvaluatedClauses:\n",
    "        EvaluatedKB = False\n",
    "    else:\n",
    "        EvaluatedKB = None\n",
    "\n",
    "    return EvaluatedKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea72f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def BackTrackingSearch(Clauses, Model):\n",
    "    EvaluatedClauses = EvaluateKB(Clauses, Model)\n",
    "    if EvaluatedClauses is True:\n",
    "        return True, Model\n",
    "    elif EvaluatedClauses is False:\n",
    "        return False, None\n",
    "    else:\n",
    "        Model2 = copy.deepcopy(Model)\n",
    "        NextSymbol = [i for i in Model2 if Model2[i] is None][0]\n",
    "        Model2[NextSymbol] = True\n",
    "        ModelTrue, SATModel = BackTrackingSearch(Clauses, Model2)\n",
    "        if ModelTrue:\n",
    "            return True, SATModel\n",
    "        Model2[NextSymbol] = False\n",
    "        ModelFalse, SATModel = BackTrackingSearch(Clauses, Model2)\n",
    "        if ModelFalse:\n",
    "            return True, SATModel\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e47685",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'AF': False,\n",
       "  'AG': False,\n",
       "  'AH': True,\n",
       "  'BF': True,\n",
       "  'BG': False,\n",
       "  'BH': False,\n",
       "  'CF': False,\n",
       "  'CG': True,\n",
       "  'CH': False,\n",
       "  'A65': True,\n",
       "  'A70': False,\n",
       "  'A75': False,\n",
       "  'B65': False,\n",
       "  'B70': False,\n",
       "  'B75': True,\n",
       "  'C65': False,\n",
       "  'C70': True,\n",
       "  'C75': False,\n",
       "  'A2': False,\n",
       "  'A3': False,\n",
       "  'A4': True,\n",
       "  'B2': False,\n",
       "  'B3': True,\n",
       "  'B4': False,\n",
       "  'C2': True,\n",
       "  'C3': False,\n",
       "  'C4': False})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clauses = [\n",
    "   #1\n",
    "    ('~CF',),\n",
    "    ('~C75',),#R1\n",
    "    ('CG', 'CH'),#R2\n",
    "    ('~AF','BG','BH'),#R3\n",
    "    ('~BF','AG','AH'),#R4\n",
    "    #2\n",
    "    ('~BH', '~B2'),#R5\n",
    "    ('BG','BF'),#R6\n",
    "    ('B3','B4'),#R7\n",
    "    ('AH','CH'),#R8\n",
    "    ('A2','C2'),#R9\n",
    "    ('~AH', 'C2'),#R10\n",
    "    ('~AH','A3','A4'),#R11\n",
    "    ('~AH','CG','CF'),#R12\n",
    "    ('~CH','AG','AF'),#R13\n",
    "    ('~CH','C3','C4'),#R14\n",
    "    ('~C2', 'A3','A4'),#R15\n",
    "    ('~A2','C3','C4'),#R16\n",
    "   \n",
    "    #3\n",
    "    ('~CG','C70'),#R17\n",
    "    ('~CF','C70'),#R18\n",
    "    ('~BF','B75'),#R19\n",
    "    ('~AF','A75'),#R20\n",
    "    ('~CH','C65'),#R21\n",
    "    ('~CH','BF','B70'),#R22\n",
    "    ('~CH','AF','A70'),#R23\n",
    "    \n",
    "    #4\n",
    "    ('~C3',),\n",
    "    ('~C75',),#R24\n",
    "    ('A3','B3'),#R25\n",
    "    ('C4','C2'),#R26\n",
    "    ('~C70','A75','B75'),#R27\n",
    "    \n",
    "    #5\n",
    "    ('~A2',),#R28\n",
    "    ('A3', 'A4'),#R29\n",
    "    ('~B2','C3','C4'),#R30\n",
    "    ('~B2','A4','A3'),#R31\n",
    "    ('~C2','B3','B4'),#R32\n",
    "    ('~C2','A4'),#R33\n",
    "    \n",
    "    #Constraints\n",
    "    ('AH', 'AG', 'AF'), \n",
    "    ('~AH', '~AG'), \n",
    "    ('~AH', '~AF'), \n",
    "    ('~AF', '~AG'),\n",
    "    ('BH', 'BG', 'BF'), \n",
    "    ('~BH', '~BG'), \n",
    "    ('~BH', '~BF'), \n",
    "    ('~BF', '~BG'),\n",
    "    ('CH', 'CG', 'CF'), \n",
    "    ('~CH', '~CG'), \n",
    "    ('~CH', '~CF'), \n",
    "    ('~CF', '~CG'),\n",
    "    ('A65', 'A70', 'A75'), \n",
    "    ('~A65', '~A70'), \n",
    "    ('~A65', '~A75'), \n",
    "    ('~A75', '~A70'),\n",
    "    ('B65', 'B70', 'B75'), \n",
    "    ('~B65', '~B70'), \n",
    "    ('~B65', '~B75'), \n",
    "    ('~B75', '~B70'),\n",
    "    ('C65', 'C70', 'C75'), \n",
    "    ('~C65', '~C70'), \n",
    "    ('~C65', '~C75'), \n",
    "    ('~C75', '~C70'),\n",
    "    ('A2', 'A3', 'A4'), \n",
    "    ('~A2', '~A3'), \n",
    "    ('~A2', '~A4'), \n",
    "    ('~A3', '~A4'),\n",
    "    ('B2', 'B3', 'B4'), \n",
    "    ('~B2', '~B3'), \n",
    "    ('~B2', '~B4'), \n",
    "    ('~B3', '~B4'),\n",
    "    ('C2', 'C3', 'C4'), \n",
    "    ('~C2', '~C3'), \n",
    "    ('~C2', '~C4'), \n",
    "    ('~C3', '~C4'),\n",
    "]\n",
    "\n",
    "Symbols = (\n",
    "    'AF', 'AG', 'AH', 'BF', 'BG', 'BH', 'CF', 'CG', 'CH', \n",
    "    'A65', 'A70', 'A75', 'B65', 'B70', 'B75', \n",
    "    'C65', 'C70', 'C75', 'A2', 'A3', 'A4', \n",
    "    'B2', 'B3', 'B4', 'C2', 'C3', 'C4'\n",
    ")\n",
    "# model = {i: None for i in Symbols}\n",
    "# _, unique_model = BackTrackingSearch(Clauses, model)\n",
    "# print(unique_model)\n",
    "\n",
    "model = {i: None for i in Symbols}\n",
    "_, model = BackTrackingSearch(Clauses, model)\n",
    "BackTrackingSearch(Clauses, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb0176",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bdb359",
   "metadata": {},
   "source": [
    "### Hence a model that satisfies the knowledge base is derived from above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d5b7f4",
   "metadata": {},
   "source": [
    "## c. Determining uniqueness of the KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5062f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=True\n",
    "F=False\n",
    "\n",
    "model = [T,F,T,T,F,T,T,F,T,F,T,T,F,F,T,T,F,T,F,T,T,T,F,F,T,F,T,F,F,T,T,F,F,T,T,T,F,T,F,F,F,F,T,T,F,T,F,T,T,T,F]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394cf6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "True Model 1: (False, True, False, False, False, True, True, False, False, False, False, True, False, True, False, True, False, False, True, False, False, False, False, True, False, True, False)\n",
      "Result: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "===\n",
      "There are 1 models for which the KB is True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "implies= lambda P,Q: (not P) or Q\n",
    "Constraint = lambda P,Q,R: (P and not Q and not R) or ( not P and Q and not R) or (not P and not Q and R)\n",
    "\n",
    "KnowledgeBase =[\n",
    "    lambda model: not model[2] and not model[26],# R1\n",
    "    lambda model: model[5] or model[8],#R2\n",
    "    lambda model: implies((model[0]),(model[4] or model[7])), #R3\n",
    "    lambda model: implies((model[1]),(model[3] or model[6])), #R4\n",
    "    lambda model: not model[7] or not model[10],#R5\n",
    "    lambda model: model[4] or model[1],#R6\n",
    "    lambda model: model[13] or model[16],#R7\n",
    "    lambda model: model[6] or model[8],#R8\n",
    "    lambda model: model[9] or model[11],#R9\n",
    "    lambda model: implies((model[6]),(model[11])),#R10\n",
    "    lambda model: implies((model[6]),(model[12] or model[15])),#R11\n",
    "    lambda model: implies((model[6]),(model[5] or model[2])),#R12\n",
    "    lambda model: implies((model[8]),(model[14] or model[17])),#R13\n",
    "    lambda model: implies((model[8]),(model[3] or model[0])),#R14\n",
    "    lambda model: implies((model[11]),(model[12] or model[15])),#R15\n",
    "    lambda model: implies((model[9]),(model[14] or model[17])),#R16\n",
    "    lambda model: implies((model[5]),(model[23])),#R17\n",
    "    lambda model: implies((model[2]),(model[23])),#R18\n",
    "    lambda model: implies((model[1]),(model[25])),#R19\n",
    "    lambda model: implies((model[0]),(model[24])),#R20\n",
    "    lambda model: implies((model[8]),(model[20])),#R21\n",
    "    lambda model: implies((model[8]),(model[1] or model[22])),#R22\n",
    "    lambda model: implies((model[8]),(model[0] or model[21])),#R23\n",
    "    lambda model: not model[14] and not model[26],#R24\n",
    "    lambda model: model[12] or model[13],#R25\n",
    "    lambda model: model[17] or model[11],#R26\n",
    "    lambda model: implies((model[23]),(model[24] or model[25])),#R27\n",
    "    lambda model: not model[9],#R28\n",
    "    lambda model: model[12] or model[15],#R29\n",
    "    lambda model: implies((model[10]),(model[14] or model[17])),#R30\n",
    "    lambda model: implies((model[10]),(model[12] or model[15])),#R31\n",
    "    lambda model: implies((model[11]),(model[13] or model[16])),#R32\n",
    "    lambda model: implies((model[11]),(model[15])),#R33\n",
    "    lambda model : Constraint(model[0],model[1],model[2]), # R34\n",
    "    lambda model : Constraint(model[3],model[4],model[5]), # R35\n",
    "    lambda model : Constraint(model[6],model[7],model[8]), # R36\n",
    "    lambda model : Constraint(model[9],model[10],model[11]), # R37\n",
    "    lambda model : Constraint(model[12],model[13],model[14]), # R38\n",
    "    lambda model : Constraint(model[15],model[16],model[17]), # R39\n",
    "    lambda model : Constraint(model[18],model[19],model[20]), # R40\n",
    "    lambda model : Constraint(model[21],model[22],model[23]), # R41\n",
    "    lambda model : Constraint(model[24],model[25],model[26]), # R142\n",
    "    lambda model : Constraint(model[0],model[3],model[6]), # R43\n",
    "    lambda model : Constraint(model[1],model[4],model[7]), # R44\n",
    "    lambda model : Constraint(model[2],model[5],model[8]), # R45\n",
    "    lambda model : Constraint(model[9],model[12],model[15]), # R46\n",
    "    lambda model : Constraint(model[10],model[13],model[16]), # R47\n",
    "    lambda model : Constraint(model[11],model[14],model[17]), # R48\n",
    "    lambda model : Constraint(model[18],model[21],model[24]), # R49\n",
    "    lambda model : Constraint(model[19],model[22],model[25]), # R50\n",
    "    lambda model : Constraint(model[20],model[23],model[26]), # R51\n",
    "                ]\n",
    "   \n",
    "import functools\n",
    "def evaluateKB(Model, KnowledgeBase):\n",
    "    Result = [KB(Model) for KB in KnowledgeBase]  # Evaluate each sentence in the knowledge base for the model\n",
    "    TrueFalse = functools.reduce(lambda a, b: a and b, Result)  # Use a reduce operation to compute the logical AND of all sentence truth values\n",
    "    return TrueFalse, Result\n",
    "\n",
    "import itertools\n",
    "TrueModelCount = 0\n",
    "Models = itertools.product([True,False], repeat = 27)\n",
    "for model in Models:\n",
    "    TF, Result = evaluateKB(model,KnowledgeBase)\n",
    "    if TF:\n",
    "        TrueModelCount+=1\n",
    "        print(f\"---\\nTrue Model {TrueModelCount}: {model}\")\n",
    "        print(f\"Result: {Result}\")\n",
    "print(f\"===\\nThere are {TrueModelCount} models for which the KB is True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42770c",
   "metadata": {},
   "source": [
    "### Hence the model is uniquely satisfiable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1511f8ce",
   "metadata": {},
   "source": [
    "## d. Improving the backtracking search method by eliminating “trivial solutions” entailed by so-called unit clauses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c739cc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model from Unit Clauses: {'C3': False, 'C75': False, 'CF': False, 'A2': False}\n",
      "Final Model: (True, {'AF': False, 'AG': False, 'AH': True, 'BF': True, 'BG': False, 'BH': False, 'CF': False, 'CG': True, 'CH': False, 'A65': True, 'A70': False, 'A75': False, 'B65': False, 'B70': False, 'B75': True, 'C65': False, 'C70': True, 'C75': False, 'A2': False, 'A3': False, 'A4': True, 'B2': False, 'B3': True, 'B4': False, 'C2': True, 'C3': False, 'C4': False}, 24)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_unit_clauses(Clauses):\n",
    "    unit_literals = set()\n",
    "    \n",
    "    for clause in Clauses:\n",
    "        if len(clause) == 1:\n",
    "            unit_literals.add(clause[0])\n",
    "\n",
    "    model = {}\n",
    "    for literal in unit_literals:\n",
    "        if literal[0] == '~':\n",
    "            model[literal[1:]] = False\n",
    "        else:\n",
    "            model[literal] = True\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "initial_model = preprocess_unit_clauses(Clauses)\n",
    "print(\"Initial Model from Unit Clauses:\", initial_model)\n",
    "\n",
    "# Merge the initial model with the model used in BackTrackingSearch\n",
    "model.update(initial_model)\n",
    "\n",
    "# Run the BackTrackingSearch with the merged model\n",
    "final_model = BackTrackingSearch(Clauses, model)\n",
    "\n",
    "# Print the final model\n",
    "print(\"Final Model:\", final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45548346",
   "metadata": {},
   "source": [
    "## e. Number of models  evaluated before a solution was found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c1f70",
   "metadata": {},
   "source": [
    "###  Evaluation of number of models for backtracking search (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba5d0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model: {'AF': False, 'AG': False, 'AH': True, 'BF': True, 'BG': False, 'BH': False, 'CF': False, 'CG': True, 'CH': False, 'A65': True, 'A70': False, 'A75': False, 'B65': False, 'B70': False, 'B75': True, 'C65': False, 'C70': True, 'C75': False, 'A2': False, 'A3': False, 'A4': True, 'B2': False, 'B3': True, 'B4': False, 'C2': True, 'C3': False, 'C4': False}\n",
      "Number of Models Evaluated: 28\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def EvaluateKB(Clauses, Model):\n",
    "    EvaluatedClauses = []\n",
    "    for clause in Clauses:\n",
    "        EvaluatedLiterals = []\n",
    "        for literal in clause:\n",
    "            if literal[0] == '~':\n",
    "                negated_literal = literal[1:]\n",
    "                if Model.get(negated_literal) is None:\n",
    "                    EvaluatedLiterals.append(None)\n",
    "                else:\n",
    "                    EvaluatedLiterals.append(not Model[negated_literal])\n",
    "            else:\n",
    "                if Model.get(literal) is None:\n",
    "                    EvaluatedLiterals.append(None)\n",
    "                else:\n",
    "                    EvaluatedLiterals.append(Model[literal])\n",
    "        if True in EvaluatedLiterals:\n",
    "            EvaluatedClauses.append(True)\n",
    "        elif None in EvaluatedLiterals:\n",
    "            EvaluatedClauses.append(None)\n",
    "        else:\n",
    "            EvaluatedClauses.append(False)\n",
    "\n",
    "    if all(i is True for i in EvaluatedClauses):\n",
    "        EvaluatedKB = True\n",
    "    elif False in EvaluatedClauses:\n",
    "        EvaluatedKB = False\n",
    "    else:\n",
    "        EvaluatedKB = None\n",
    "\n",
    "    return EvaluatedKB\n",
    "def BackTrackingSearch(Clauses, Model, evaluation_count=0):\n",
    "    EvaluatedClauses = EvaluateKB(Clauses, Model)\n",
    "    evaluation_count += 1  # Increment the evaluation count\n",
    "\n",
    "    if EvaluatedClauses is True:\n",
    "        return True, Model, evaluation_count\n",
    "    elif EvaluatedClauses is False:\n",
    "        return False, None, evaluation_count\n",
    "    else:\n",
    "        Model2 = copy.deepcopy(Model)\n",
    "        NextSymbol = [i for i in Model2 if Model2[i] is None][0]\n",
    "        Model2[NextSymbol] = True\n",
    "        ModelTrue, SATModel, count_true = BackTrackingSearch(Clauses, Model2, evaluation_count)\n",
    "        if ModelTrue:\n",
    "            return True, SATModel, count_true\n",
    "\n",
    "        Model2[NextSymbol] = False\n",
    "        ModelFalse, SATModel, count_false = BackTrackingSearch(Clauses, Model2, evaluation_count)\n",
    "        if ModelFalse:\n",
    "            return True, SATModel, count_false\n",
    "\n",
    "    return False, None, evaluation_count\n",
    "Clauses = [\n",
    "   #1\n",
    "    ('~CF',),\n",
    "    ('~C75',),#R1\n",
    "    ('CG', 'CH'),#R2\n",
    "    ('~AF','BG','BH'),#R3\n",
    "    ('~BF','AG','AH'),#R4\n",
    "    #2\n",
    "    ('~BH', '~B2'),#R5\n",
    "    ('BG','BF'),#R6\n",
    "    ('B3','B4'),#R7\n",
    "    ('AH','CH'),#R8\n",
    "    ('A2','C2'),#R9\n",
    "    ('~AH', 'C2'),#R10\n",
    "    ('~AH','A3','A4'),#R11\n",
    "    ('~AH','CG','CF'),#R12\n",
    "    ('~CH','C3','C4'),#R13\n",
    "    ('~CH','AG','AF'),#R14\n",
    "    ('~C2', 'A3','A4'),#R15\n",
    "    ('~A2','C3','C4'),#R16\n",
    "   \n",
    "    #3\n",
    "    ('~CG','C70'),#R17\n",
    "    ('~CF','C70'),#R18\n",
    "    ('~BF','B75'),#R19\n",
    "    ('~AF','A75'),#R20\n",
    "    ('~CH','C65'),#R21\n",
    "    ('~CH','BF','B70'),#R22\n",
    "    ('~CH','AF','A70'),#R23\n",
    "    \n",
    "    #4\n",
    "    ('~C3',),\n",
    "    ('~C75',),#R24\n",
    "    ('A3','B3'),#R25\n",
    "    ('C4','C2'),#R26\n",
    "    ('~C70','A75','B75'),#R27\n",
    "    \n",
    "    #5\n",
    "    ('~A2',),#R28\n",
    "    ('A3', 'A4'),#R29\n",
    "    ('~B2','C3','C4'),#R30\n",
    "    ('~B2','A4','A3'),#R31\n",
    "    ('~C2','B3','B4'),#R32\n",
    "    ('~C2','A4'),#R33\n",
    "    \n",
    "    #Constraints\n",
    "    ('AH', 'AG', 'AF'), \n",
    "    ('~AH', '~AG'), \n",
    "    ('~AH', '~AF'), \n",
    "    ('~AF', '~AG'),\n",
    "    ('BH', 'BG', 'BF'), \n",
    "    ('~BH', '~BG'), \n",
    "    ('~BH', '~BF'), \n",
    "    ('~BF', '~BG'),\n",
    "    ('CH', 'CG', 'CF'), \n",
    "    ('~CH', '~CG'), \n",
    "    ('~CH', '~CF'), \n",
    "    ('~CF', '~CG'),\n",
    "    ('A65', 'A70', 'A75'), \n",
    "    ('~A65', '~A70'), \n",
    "    ('~A65', '~A75'), \n",
    "    ('~A75', '~A70'),\n",
    "    ('B65', 'B70', 'B75'), \n",
    "    ('~B65', '~B70'), \n",
    "    ('~B65', '~B75'), \n",
    "    ('~B75', '~B70'),\n",
    "    ('C65', 'C70', 'C75'), \n",
    "    ('~C65', '~C70'), \n",
    "    ('~C65', '~C75'), \n",
    "    ('~C75', '~C70'),\n",
    "    ('A2', 'A3', 'A4'), \n",
    "    ('~A2', '~A3'), \n",
    "    ('~A2', '~A4'), \n",
    "    ('~A3', '~A4'),\n",
    "    ('B2', 'B3', 'B4'), \n",
    "    ('~B2', '~B3'), \n",
    "    ('~B2', '~B4'), \n",
    "    ('~B3', '~B4'),\n",
    "    ('C2', 'C3', 'C4'), \n",
    "    ('~C2', '~C3'), \n",
    "    ('~C2', '~C4'), \n",
    "    ('~C3', '~C4'),\n",
    "]\n",
    "\n",
    "Symbols = (\n",
    "    'AF', 'AG', 'AH', 'BF', 'BG', 'BH', 'CF', 'CG', 'CH', \n",
    "    'A65', 'A70', 'A75', 'B65', 'B70', 'B75', \n",
    "    'C65', 'C70', 'C75', 'A2', 'A3', 'A4', \n",
    "    'B2', 'B3', 'B4', 'C2', 'C3', 'C4'\n",
    ")\n",
    "\n",
    "model = {i: None for i in Symbols}\n",
    "_, final_model, evaluation_count = BackTrackingSearch(Clauses, model)\n",
    "print(\"Final Model:\", final_model)\n",
    "print(\"Number of Models Evaluated:\", evaluation_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f29d8f",
   "metadata": {},
   "source": [
    "### Here, the final result is obtained after the backtracking search is done on 28 models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080b4dd",
   "metadata": {},
   "source": [
    "### Evaluation of models for uniquely satisfiable model (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7236455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "True Model 1: (False, True, False, False, False, True, True, False, False, False, False, True, False, True, False, True, False, False, True, False, False, False, False, True, False, True, False)\n",
      "Result: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "Models evaluated before solution: 97474294\n",
      "===\n",
      "There are 1 models for which the KB is True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "T = True\n",
    "F = False\n",
    "\n",
    "model = [T, F, T, T, F, T, T, F, T, F, T, T, F, F, T, T, F, T, F, T, T, T, F, F, T, F, T, F, F, T, T, F, F, T, T, T, F, T, F, F, F, F, T, T, F, T, F, T, T, T, F]\n",
    "\n",
    "implies = lambda P, Q: (not P) or Q\n",
    "Constraint = lambda P, Q, R: (P and not Q and not R) or (not P and Q and not R) or (not P and not Q and R)\n",
    "\n",
    "KnowledgeBase = [\n",
    "    lambda model: not model[2] and not model[26],# R1\n",
    "    lambda model: model[5] or model[8],#R2\n",
    "    lambda model: implies((model[0]),(model[4] or model[7])), #R3\n",
    "    lambda model: implies((model[1]),(model[3] or model[6])), #R4\n",
    "    lambda model: not model[7] or not model[10],#R5\n",
    "    lambda model: model[4] or model[1],#R6\n",
    "    lambda model: model[13] or model[16],#R7\n",
    "    lambda model: model[6] or model[8],#R8\n",
    "    lambda model: model[9] or model[11],#R9\n",
    "    lambda model: implies((model[6]),(model[11])),#R10\n",
    "    lambda model: implies((model[6]),(model[12] or model[15])),#R11\n",
    "    lambda model: implies((model[6]),(model[5] or model[2])),#R12\n",
    "    lambda model: implies((model[8]),(model[14] or model[17])),#R13\n",
    "    lambda model: implies((model[8]),(model[3] or model[0])),#R14\n",
    "    lambda model: implies((model[11]),(model[12] or model[15])),#R15\n",
    "    lambda model: implies((model[9]),(model[14] or model[17])),#R16\n",
    "    lambda model: implies((model[5]),(model[23])),#R17\n",
    "    lambda model: implies((model[2]),(model[23])),#R18\n",
    "    lambda model: implies((model[1]),(model[25])),#R19\n",
    "    lambda model: implies((model[0]),(model[24])),#R20\n",
    "    lambda model: implies((model[8]),(model[20])),#R21\n",
    "    lambda model: implies((model[8]),(model[1] or model[22])),#R22\n",
    "    lambda model: implies((model[8]),(model[0] or model[21])),#R23\n",
    "    lambda model: not model[14] and not model[26],#R24\n",
    "    lambda model: model[12] or model[13],#R25\n",
    "    lambda model: model[17] or model[11],#R26\n",
    "    lambda model: implies((model[23]),(model[24] or model[25])),#R27\n",
    "    lambda model: not model[9],#R28\n",
    "    lambda model: model[12] or model[15],#R29\n",
    "    lambda model: implies((model[10]),(model[14] or model[17])),#R30\n",
    "    lambda model: implies((model[10]),(model[12] or model[15])),#R31\n",
    "    lambda model: implies((model[11]),(model[13] or model[16])),#R32\n",
    "    lambda model: implies((model[11]),(model[15])),#R33\n",
    "    lambda model : Constraint(model[0],model[1],model[2]), # R34\n",
    "    lambda model : Constraint(model[3],model[4],model[5]), # R35\n",
    "    lambda model : Constraint(model[6],model[7],model[8]), # R36\n",
    "    lambda model : Constraint(model[9],model[10],model[11]), # R37\n",
    "    lambda model : Constraint(model[12],model[13],model[14]), # R38\n",
    "    lambda model : Constraint(model[15],model[16],model[17]), # R39\n",
    "    lambda model : Constraint(model[18],model[19],model[20]), # R40\n",
    "    lambda model : Constraint(model[21],model[22],model[23]), # R41\n",
    "    lambda model : Constraint(model[24],model[25],model[26]), # R142\n",
    "    lambda model : Constraint(model[0],model[3],model[6]), # R43\n",
    "    lambda model : Constraint(model[1],model[4],model[7]), # R44\n",
    "    lambda model : Constraint(model[2],model[5],model[8]), # R45\n",
    "    lambda model : Constraint(model[9],model[12],model[15]), # R46\n",
    "    lambda model : Constraint(model[10],model[13],model[16]), # R47\n",
    "    lambda model : Constraint(model[11],model[14],model[17]), # R48\n",
    "    lambda model : Constraint(model[18],model[21],model[24]), # R49\n",
    "    lambda model : Constraint(model[19],model[22],model[25]), # R50\n",
    "    lambda model : Constraint(model[20],model[23],model[26]), # R51\n",
    "                ]\n",
    "\n",
    "import functools\n",
    "\n",
    "def evaluateKB(Model, KnowledgeBase, counter):\n",
    "    Result = [KB(Model) for KB in KnowledgeBase]  # Evaluate each sentence in the knowledge base for the model\n",
    "    TrueFalse = functools.reduce(lambda a, b: a and b, Result)  # Use a reduce operation to compute the logical AND of all sentence truth values\n",
    "    counter[0] += 1  # Increment the counter\n",
    "    return TrueFalse, Result\n",
    "\n",
    "import itertools\n",
    "\n",
    "TrueModelCount = 0\n",
    "Models = itertools.product([T, F], repeat=27)\n",
    "counter = [0]  # Counter to keep track of the number of models evaluated\n",
    "\n",
    "for model in Models:\n",
    "    TF, Result = evaluateKB(model, KnowledgeBase, counter)\n",
    "    if TF:\n",
    "        TrueModelCount += 1\n",
    "        print(f\"---\\nTrue Model {TrueModelCount}: {model}\")\n",
    "        print(f\"Result: {Result}\")\n",
    "        print(f\"Models evaluated before solution: {counter[0]}\")\n",
    "        break  # Stop after finding the first true model\n",
    "\n",
    "print(f\"===\\nThere are {TrueModelCount} models for which the KB is True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dcdfc9",
   "metadata": {},
   "source": [
    "### The number of models evaluated before finding 1 true model is 97474294 models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18480311",
   "metadata": {},
   "source": [
    "### Evaluating number of models for improved backtracking search (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff96fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model from Unit Clauses: {'C3': False, 'C75': False, 'CF': False, 'A2': False}\n",
      "Final Model: {'AF': False, 'AG': False, 'AH': True, 'BF': True, 'BG': False, 'BH': False, 'CF': False, 'CG': True, 'CH': False, 'A65': True, 'A70': False, 'A75': False, 'B65': False, 'B70': False, 'B75': True, 'C65': False, 'C70': True, 'C75': False, 'A2': False, 'A3': False, 'A4': True, 'B2': False, 'B3': True, 'B4': False, 'C2': True, 'C3': False, 'C4': False}\n",
      "Number of models evaluated: 24\n"
     ]
    }
   ],
   "source": [
    "def preprocess_unit_clauses(Clauses):\n",
    "    unit_literals = set()\n",
    "\n",
    "    for clause in Clauses:\n",
    "        if len(clause) == 1:\n",
    "            unit_literals.add(clause[0])\n",
    "\n",
    "    model = {}\n",
    "    for literal in unit_literals:\n",
    "        if literal[0] == '~':\n",
    "            model[literal[1:]] = False\n",
    "        else:\n",
    "            model[literal] = True\n",
    "\n",
    "    return model\n",
    "\n",
    "initial_model = preprocess_unit_clauses(Clauses)\n",
    "print(\"Initial Model from Unit Clauses:\", initial_model)\n",
    "\n",
    "# Merge the initial model with the model used in BackTrackingSearch\n",
    "model_copy = dict(model)  # Make a copy of the original model\n",
    "model_copy.update(initial_model)\n",
    "\n",
    "# Run the BackTrackingSearch with the merged model\n",
    "result_tuple = BackTrackingSearch(Clauses, model_copy)\n",
    "result, final_model, evaluation_count = result_tuple\n",
    "\n",
    "# Print the final model and the number of models evaluated\n",
    "print(\"Final Model:\", final_model)\n",
    "print(\"Number of models evaluated:\", evaluation_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0fd10",
   "metadata": {},
   "source": [
    "### Here, the number of models evaluated for the improved backtracking search is 24. This is the expected result as the number of evaluated models is less than backtracking without tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d7e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
